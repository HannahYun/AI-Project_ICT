{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e560e473",
   "metadata": {},
   "source": [
    "# 1. 텍스트 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c08ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 13.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib in c:\\users\\ictai\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\ictai\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.7.25-cp38-cp38-win_amd64.whl (262 kB)\n",
      "     ---------------------------------------- 262.8/262.8 kB ? eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\ictai\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.7 regex-2022.7.25 tqdm-4.64.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk #token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131987ef",
   "metadata": {},
   "source": [
    "- anaconda3에는 기본 설치되어 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4bdc27",
   "metadata": {},
   "source": [
    "## (1) 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7ba143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ictai\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 3\n",
      "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
    "               You can see it out your window or on your television. \\\n",
    "               You feel it when you go to work, or go to church or pay your taxes.'\n",
    "\n",
    "sentences = sent_tokenize(text = text_sample)\n",
    "print(type(sentences),len(sentences))\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb12af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 4\n",
      "['구글이 11일 구글 I/O 2022에서 실시간으로 언어를 번역할 수 있는 증강현실(AR) 안경을 공개했다.', '안경을 쓰고 있으면 상대방의 말이 번역돼 안경 렌즈에 표시된다.', '구글은 AR 안경을 사용해 북경어에서 영어로 또는 그 반대로, 영어에서 스페인어로 번역하고,청각 장애인이나 난청이 있는 사람들에게 읽을 수 있는 텍스트를 제공해 보청기 없이도 의사 소통할 수 있는 방법을 보여주었다.', '구글의 AR 안경은 기능은 물론 모양과 디자인도 일반 안경처럼 평범하고 단순해보이지만 더 많은 증강 현실 기능을 추가한다면 매력적인 제품이 될 수 있을 것으로 보인다.']\n"
     ]
    }
   ],
   "source": [
    "text_sample = '구글이 11일 구글 I/O 2022에서 실시간으로 언어를 번역할 수 있는 \\\n",
    "증강현실(AR) 안경을 공개했다. 안경을 쓰고 있으면 상대방의 말이 번역돼 안경 렌즈에 표시된다.\\\n",
    " 구글은 AR 안경을 사용해 북경어에서 영어로 또는 그 반대로, 영어에서 스페인어로 번역하고,\\\n",
    "청각 장애인이나 난청이 있는 사람들에게 읽을 수 있는 텍스트를 제공해 \\\n",
    "보청기 없이도 의사 소통할 수 있는 방법을 보여주었다. \\\n",
    "구글의 AR 안경은 기능은 물론 모양과 디자인도 일반 안경처럼 평범하고 단순해보이지만 \\\n",
    "더 많은 증강 현실 기능을 추가한다면 매력적인 제품이 될 수 있을 것으로 보인다.'\n",
    "\n",
    "sentences = sent_tokenize(text = text_sample)\n",
    "print(type(sentences), len(sentences))\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b0b2b",
   "metadata": {},
   "source": [
    "## (2) 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e86ead41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 43\n",
      "['안경을', '쓰고', '있으면', '상대방의', '말이', '번역돼', '안경', '렌즈에', '표시된다', '.', '구글은', 'AR', '안경을', '사용해', '북경어에서', '영어로', '또는', '그', '반대로', ',', '영어에서', '스페인어로', '번역하고', ',', '청각', '장애인이나', '난청이', '있는', '사람들에게', '읽을', '수', '있는', '텍스트를', '제공해', '보청기', '없이도', '의사', '소통할', '수', '있는', '방법을', '보여주었다', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "text_sample = '안경을 쓰고 있으면 상대방의 말이 번역돼 안경 렌즈에 표시된다.\\\n",
    " 구글은 AR 안경을 사용해 북경어에서 영어로 또는 그 반대로, 영어에서 스페인어로 번역하고,\\\n",
    "청각 장애인이나 난청이 있는 사람들에게 읽을 수 있는 텍스트를 제공해 \\\n",
    "보청기 없이도 의사 소통할 수 있는 방법을 보여주었다.'\n",
    "\n",
    "words = word_tokenize(text_sample)\n",
    "print(type(words),len(words))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe24b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 4\n",
      "[['구글이', '11일', '구글', 'I/O', '2022에서', '실시간으로', '언어를', '번역할', '수', '있는', '증강현실', '(', 'AR', ')', '안경을', '공개했다', '.'], ['안경을', '쓰고', '있으면', '상대방의', '말이', '번역돼', '안경', '렌즈에', '표시된다', '.'], ['구글은', 'AR', '안경을', '사용해', '북경어에서', '영어로', '또는', '그', '반대로', ',', '영어에서', '스페인어로', '번역하고', ',', '청각', '장애인이나', '난청이', '있는', '사람들에게', '읽을', '수', '있는', '텍스트를', '제공해', '보청기', '없이도', '의사', '소통할', '수', '있는', '방법을', '보여주었다', '.'], ['구글의', 'AR', '안경은', '기능은', '물론', '모양과', '디자인도', '일반', '안경처럼', '평범하고', '단순해보이지만', '더', '많은', '증강', '현실', '기능을', '추가한다면', '매력적인', '제품이', '될', '수', '있을', '것으로', '보인다', '.']]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "#여러개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화 만드는 함수 생성\n",
    "def tokenize_text(text):\n",
    " \n",
    "    #문장별로 분리 토큰\n",
    "    sentences = sent_tokenize(text)\n",
    "     \n",
    "    #분리된 문장별 단어 토큰화\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "    return word_tokens\n",
    "\n",
    "#여러 문장들에 대해 문장별 단어 토큰화 수행. \n",
    "text_sample = '구글이 11일 구글 I/O 2022에서 실시간으로 언어를 번역할 수 있는 \\\n",
    "증강현실(AR) 안경을 공개했다. 안경을 쓰고 있으면 상대방의 말이 번역돼 안경 렌즈에 표시된다.\\\n",
    " 구글은 AR 안경을 사용해 북경어에서 영어로 또는 그 반대로, 영어에서 스페인어로 번역하고,\\\n",
    "청각 장애인이나 난청이 있는 사람들에게 읽을 수 있는 텍스트를 제공해 \\\n",
    "보청기 없이도 의사 소통할 수 있는 방법을 보여주었다. \\\n",
    "구글의 AR 안경은 기능은 물론 모양과 디자인도 일반 안경처럼 평범하고 단순해보이지만 \\\n",
    "더 많은 증강 현실 기능을 추가한다면 매력적인 제품이 될 수 있을 것으로 보인다.'\n",
    "\n",
    "word_tokens = tokenize_text(text_sample)\n",
    "print(type(word_tokens),len(word_tokens))\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f143417",
   "metadata": {},
   "source": [
    "## (3) 스톱 워드 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4923be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ictai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62d24a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 stop words 갯수: 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "print('영어 stop words 갯수:',len(stopWords))\n",
    "print(stopWords[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59de77cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its : True\n",
      "as : True\n",
      "that : True\n",
      "this : True\n",
      "of : True\n",
      "which : True\n",
      "and : True\n"
     ]
    }
   ],
   "source": [
    "for word in ['its', 'as', 'that', 'this', 'of', 'which', 'and']:\n",
    "    print(word,':', word in stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc20a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['artificial', 'intelligence', '(', 'ai', ')', 'intelligence', 'demonstrated', 'machines', ',', 'opposed', 'natural', 'intelligence', 'displayed', 'animals', 'including', 'humans', '.'], ['ai', 'research', 'defined', 'field', 'study', 'intelligent', 'agents', ',', 'refers', 'system', 'perceives', 'environment', 'takes', 'actions', 'maximize', 'chance', 'achieving', 'goals', '.']]\n"
     ]
    }
   ],
   "source": [
    "text_sample = \"\"\"Artificial intelligence (AI) is intelligence demonstrated \n",
    "by machines, as opposed to the natural intelligence displayed by animals \n",
    "including humans. \n",
    "AI research has been defined as the field of study of  \n",
    "intelligent agents, which refers to any system that perceives \n",
    "its environment and takes actions that maximize its chance of achieving its goals.\n",
    "\"\"\"\n",
    "word_tokens = tokenize_text(text_sample)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "all_tokens = []\n",
    "#위 예제의 3개의 문장별로 얻은 word_tokens list에 대해 stop word 제거 loop\n",
    "for sentence in word_tokens:\n",
    "    filtered_words=[]\n",
    "    #개별 문장별로 tokenize된  sentence list에 대해 stop word 제거 loop\n",
    "    for word in sentence:\n",
    "        word = word.lower() #소문자로 모두 변환\n",
    "        #tokenize된 개별 word가 stop words 들의 단어에 포함되지 않으면 word_tokens 제거\n",
    "        if word not in stopwords:\n",
    "            filtered_words.append(word)\n",
    "    all_tokens.append(filtered_words)\n",
    "    \n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35b8c7",
   "metadata": {},
   "source": [
    "## (4) 단어 원형 구하기: Stemming(어간추출)과 Lemmatization(표제어 추출)\n",
    "- 1) 어간(stem)\n",
    ": 단어의 의미를 담고 있는 단어의 핵심 부분.\n",
    "\n",
    "- 2) 접사(affix)\n",
    ": 단어에 추가적인 의미를 주는 부분.\n",
    "    \n",
    "- 3) 표제어(Lemma)는 한글로는 '표제어' 또는 '기본 사전형 단어' 의 의미. \n",
    "   예를 들어서 am, are, is 단어들의 표제어는 be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6791a276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work work work\n",
      "amus amus amus\n",
      "happy happiest\n",
      "fant fanciest\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
    "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
    "print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
    "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85c38323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ictai\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c561dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ictai\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a157e350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amuse amuse amuse\n",
      "happy happy\n",
      "fancy fancy\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),\n",
    "      lemma.lemmatize('amused','v'))\n",
    "print(lemma.lemmatize('happier','a'),lemma.lemmatize('happiest','a'))\n",
    "print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd2c98",
   "metadata": {},
   "source": [
    "## (5)피쳐 벡터화 (Bag of Words)\n",
    "- 단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도에만 집중하는 텍스트 데이터의 수치화 표현 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bccf55c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    " ]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b670b585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artificial intelligence ( ai ) intelligence demonstrated machines , opposed natural intelligence displayed animals including humans .', 'ai research defined field study intelligent agents , refers system perceives environment takes actions maximize chance achieving goals .']\n"
     ]
    }
   ],
   "source": [
    "corpus= [ ]\n",
    "for s in all_tokens:\n",
    "    corpus.append(\" \".join(s)) #빈칸\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c5cc568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['achieving' 'actions' 'agents' 'ai' 'animals' 'artificial' 'chance'\n",
      " 'defined' 'demonstrated' 'displayed' 'environment' 'field' 'goals'\n",
      " 'humans' 'including' 'intelligence' 'intelligent' 'machines' 'maximize'\n",
      " 'natural' 'opposed' 'perceives' 'refers' 'research' 'study' 'system'\n",
      " 'takes']\n",
      "[[0 0 0 1 1 1 0 0 1 1 0 0 0 1 1 3 0 1 0 1 1 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d316593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artificial': 5,\n",
       " 'intelligence': 15,\n",
       " 'ai': 3,\n",
       " 'demonstrated': 8,\n",
       " 'machines': 17,\n",
       " 'opposed': 20,\n",
       " 'natural': 19,\n",
       " 'displayed': 9,\n",
       " 'animals': 4,\n",
       " 'including': 14,\n",
       " 'humans': 13,\n",
       " 'research': 23,\n",
       " 'defined': 7,\n",
       " 'field': 11,\n",
       " 'study': 24,\n",
       " 'intelligent': 16,\n",
       " 'agents': 2,\n",
       " 'refers': 22,\n",
       " 'system': 25,\n",
       " 'perceives': 21,\n",
       " 'environment': 10,\n",
       " 'takes': 26,\n",
       " 'actions': 1,\n",
       " 'maximize': 18,\n",
       " 'chance': 6,\n",
       " 'achieving': 0,\n",
       " 'goals': 12}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_ #딕셔너리 형태, 각각의 단어가 몇 번 index에 해당하는 지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d35ccb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and this is' 'document is the' 'is the first' 'is the second'\n",
      " 'is the third' 'is this the' 'the first document' 'the second document'\n",
      " 'the third one' 'this document is' 'this is the' 'this the first']\n",
      "[[0 0 1 0 0 0 1 0 0 0 1 0]\n",
      " [0 1 0 1 0 0 0 1 0 1 0 0]\n",
      " [1 0 0 0 1 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    " ]\n",
    "\n",
    "vectorizer2 = CountVectorizer(analyzer = 'word', ngram_range = (3, 3))\n",
    "X2 = vectorizer2.fit_transform(corpus)\n",
    "print(vectorizer2.get_feature_names_out())\n",
    "\n",
    "print(X2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b686d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this is the': 10,\n",
       " 'is the first': 2,\n",
       " 'the first document': 6,\n",
       " 'this document is': 9,\n",
       " 'document is the': 1,\n",
       " 'is the second': 3,\n",
       " 'the second document': 7,\n",
       " 'and this is': 0,\n",
       " 'is the third': 4,\n",
       " 'the third one': 8,\n",
       " 'is this the': 5,\n",
       " 'this the first': 11}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2.vocabulary_ #딕셔너리 형태, 각각의 단어가 몇 번 index에 해당하는 지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660397b",
   "metadata": {},
   "source": [
    "### 불용어 제거하여 BOW 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb903013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document' 'second']\n",
      "[[1 0]\n",
      " [2 1]\n",
      " [0 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "#불용어 제거\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    " ]\n",
    "\n",
    "vectorizer3 = CountVectorizer(stop_words = \"english\")\n",
    "X3 = vectorizer3.fit_transform(corpus)\n",
    "print(vectorizer3.get_feature_names_out())\n",
    "\n",
    "print(X3.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7030483e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': 0, 'second': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer3.vocabulary_ #딕셔너리 형태, 각각의 단어가 몇 번 index에 해당하는 지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfd15e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document' 'first' 'second' 'third']\n",
      "[[1 1 0 0]\n",
      " [2 0 1 0]\n",
      " [0 0 0 1]\n",
      " [1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#불용어 제거\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    " ]\n",
    "\n",
    "vectorizer3 = CountVectorizer(stop_words = [\"the\", \"this\", \"and\", \"is\", \"one\"])\n",
    "X3 = vectorizer3.fit_transform(corpus)\n",
    "print(vectorizer3.get_feature_names_out())\n",
    "\n",
    "print(X3.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a5b74a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': 1, 'document': 0, 'second': 2, 'third': 3}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer3.vocabulary_ #딕셔너리 형태, 각각의 단어가 몇 번 index에 해당하는 지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ad6980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11일' '2022에서' 'ar' '것으로' '공개했다' '구글' '구글은' '구글의' '구글이' '기능은' '기능을' '난청이'\n",
      " '단순해보이지만' '디자인도' '렌즈에' '많은' '말이' '매력적인' '모양과' '물론' '반대로' '방법을' '번역돼'\n",
      " '번역하고' '번역할' '보청기' '북경어에서' '사람들에게' '사용해' '상대방의' '소통할' '스페인어로' '실시간으로'\n",
      " '쓰고' '안경' '안경은' '안경을' '안경처럼' '언어를' '없이도' '영어로' '영어에서' '의사' '일반' '읽을'\n",
      " '있으면' '있을' '장애인이나' '제공해' '제품이' '증강' '증강현실' '청각' '추가한다면' '텍스트를' '평범하고'\n",
      " '표시된다' '현실']\n",
      "[[1 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      "  1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0\n",
      "  2 0 0 1 1 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0 1 0]\n",
      " [0 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "corpus = ['구글이 11일 구글 I/O 2022에서 실시간으로 언어를 번역할 수 있는 \\\n",
    "증강현실(AR) 안경을 공개했다.', '안경을 쓰고 있으면 상대방의 말이 번역돼 안경 렌즈에 표시된다.\\\n",
    " 구글은 AR 안경을 사용해 북경어에서 영어로 또는 그 반대로, 영어에서 스페인어로 번역하고,\\\n",
    "청각 장애인이나 난청이 있는 사람들에게 읽을 수 있는 텍스트를 제공해 \\\n",
    "보청기 없이도 의사 소통할 수 있는 방법을 보여주었다.', \\\n",
    "'구글의 AR 안경은 기능은 물론 모양과 디자인도 일반 안경처럼 평범하고 단순해보이지만 \\\n",
    "더 많은 증강 현실 기능을 추가한다면 매력적인 제품이 될 수 있을 것으로 보인다.']\n",
    "vectorizer4 = CountVectorizer(stop_words=[\"또는\", \"보인다\", \"보여주었다\", \"수\", \"있는\"])\n",
    "X4 = vectorizer4.fit_transform(corpus)\n",
    "print(vectorizer4.get_feature_names_out())\n",
    "\n",
    "print(X4.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d8f0d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'구글이': 8,\n",
       " '11일': 0,\n",
       " '구글': 5,\n",
       " '2022에서': 1,\n",
       " '실시간으로': 32,\n",
       " '언어를': 38,\n",
       " '번역할': 24,\n",
       " '증강현실': 51,\n",
       " 'ar': 2,\n",
       " '안경을': 36,\n",
       " '공개했다': 4,\n",
       " '쓰고': 33,\n",
       " '있으면': 45,\n",
       " '상대방의': 29,\n",
       " '말이': 16,\n",
       " '번역돼': 22,\n",
       " '안경': 34,\n",
       " '렌즈에': 14,\n",
       " '표시된다': 56,\n",
       " '구글은': 6,\n",
       " '사용해': 28,\n",
       " '북경어에서': 26,\n",
       " '영어로': 40,\n",
       " '반대로': 20,\n",
       " '영어에서': 41,\n",
       " '스페인어로': 31,\n",
       " '번역하고': 23,\n",
       " '청각': 52,\n",
       " '장애인이나': 47,\n",
       " '난청이': 11,\n",
       " '사람들에게': 27,\n",
       " '읽을': 44,\n",
       " '텍스트를': 54,\n",
       " '제공해': 48,\n",
       " '보청기': 25,\n",
       " '없이도': 39,\n",
       " '의사': 42,\n",
       " '소통할': 30,\n",
       " '방법을': 21,\n",
       " '구글의': 7,\n",
       " '안경은': 35,\n",
       " '기능은': 9,\n",
       " '물론': 19,\n",
       " '모양과': 18,\n",
       " '디자인도': 13,\n",
       " '일반': 43,\n",
       " '안경처럼': 37,\n",
       " '평범하고': 55,\n",
       " '단순해보이지만': 12,\n",
       " '많은': 15,\n",
       " '증강': 50,\n",
       " '현실': 57,\n",
       " '기능을': 10,\n",
       " '추가한다면': 53,\n",
       " '매력적인': 17,\n",
       " '제품이': 49,\n",
       " '있을': 46,\n",
       " '것으로': 3}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer4.vocabulary_ #딕셔너리 형태, 각각의 단어가 몇 번 index에 해당하는 지"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
